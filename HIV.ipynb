{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HIV",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kxk302/HIV/blob/main/HIV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JDt_5RMdjL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95e34a19-96e2-43a2-f4ba-a85b8b457fac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0bkibi4dy-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8d901b0-7f70-43a2-87d5-fa5a8e03d499"
      },
      "source": [
        "!ls '/content/gdrive/MyDrive/Colab Notebooks'"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HIV  HIV_V3_codonmsa_macse_pre.tsv  MBA.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8BTJgr3VIiP"
      },
      "source": [
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from mlxtend.frequent_patterns import apriori\n",
        "from mlxtend.frequent_patterns import association_rules\n",
        "\n",
        "# Create a string representing nucleotide plus position\n",
        "# Pivot the data so we have all sample strings on a single line\n",
        "#\n",
        "def preprocess_input_file(df_in):\n",
        "  if df_in is None or df_in.shape[0] == 0:\n",
        "    return df_in\n",
        "  \n",
        "  df = df_in.copy()\n",
        "\n",
        "  # Create a new column called 'Label', which is a string concatentation of Nucleotide and Position values. \n",
        "  df[\"Label\"] = df[\"Nucleotide\"].astype(str) + df[\"Position\"].astype(str)\n",
        "\n",
        "  # We do not need Nucleotide, and Position columns anymore\n",
        "  df = df[[\"Sample\", \"Label\"]]\n",
        "  \n",
        "  # Add a new column called 'Value', prepopulated with 1\n",
        "  df[\"Value\"] = 1\n",
        "\n",
        "  df = pd.pivot_table(df, index=\"Sample\", columns=\"Label\", values=\"Value\")\n",
        "\n",
        "  # Set all data frame nan (not a number) values to 0\n",
        "  df = df.fillna(0)\n",
        "\n",
        "  # Convert all data framevalues to integer\n",
        "  df = df.astype(int) \n",
        "\n",
        "  return df"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VubP1ctVUsc"
      },
      "source": [
        "def get_association_rules(in_file, min_support=0.20, \n",
        "                          min_confidence=0.80, min_lift=1.0, \n",
        "                          min_conviction=1.0, max_len=None):\n",
        "  \n",
        "  # Read the input file and pick the needed columns\n",
        "  df_in = pd.read_csv(in_file, sep='\\t')[['Sample', 'Nucleotide', 'Position']]\n",
        "\n",
        "  # Preprocess the data frame\n",
        "  df = preprocess_input_file(df_in)\n",
        "\n",
        "  # Get frequent item sets, with support larger than min_support, using Apriori algorithm\n",
        "  frequent_itemsets = apriori(df, min_support=min_support, use_colnames=True, max_len=max_len)\n",
        "\n",
        "  # Get association rules, with lift larger than min_lift  \n",
        "  rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=min_lift)\n",
        "\n",
        "  # Filter association rules, keeping rules with confidence larger than min_confidence\n",
        "  rules = rules[ (rules['confidence'] >= min_confidence) & (rules['conviction'] >= min_conviction) ]\n",
        "\n",
        "  return rules\n",
        "\n",
        "def get_association_rules_param(param_dict):\n",
        "  in_file = param_dict.get('in_file', None)\n",
        "  min_support = param_dict.get('min_support', 0.20)\n",
        "  min_confidence = param_dict.get('min_confidence', 0.80)\n",
        "  min_lift = param_dict.get('min_lift', 1.0)\n",
        "  min_conviction = param_dict.get('min_conviction', 1.0)\n",
        "  max_len = param_dict.get('max_len', None)\n",
        "\n",
        "  return get_association_rules(in_file, min_support, \n",
        "                               min_confidence, min_lift, \n",
        "                               min_conviction, max_len)\n",
        "\n",
        "# Add a new column that has the distance between the head/tail positions  \n",
        "# Only makes sense if max_len is 2, that is we have rules in the form of A -> B\n",
        "def add_distance_column(df_in):\n",
        "  df = df_in.copy()\n",
        "   \n",
        "  head = df['antecedents']\n",
        "  tail = df['consequents']\n",
        "\n",
        "  head = head.astype(str)\n",
        "  tail = tail.astype(str)\n",
        "\n",
        "  # Remove forzenset chars before/after the position\n",
        "  head = head.str.slice(13,-3,1)\n",
        "  tail = tail.str.slice(13,-3,1)\n",
        "\n",
        "  head = head.astype(int)\n",
        "  tail = tail.astype(int)\n",
        "\n",
        "  # Calculate absolute value of distance between head and tail positions\n",
        "  distance = head.subtract(tail).apply(abs)\n",
        "  df['distance'] = distance\n",
        "  return df\n",
        "\n",
        "def filter_rules_based_on_distance(df_in, min_distance):\n",
        "  df = df_in.copy()\n",
        "\n",
        "  df = add_distance_column(df)\n",
        "\n",
        "  # Filter rules based on distance between head and tail positions  \n",
        "  df = df[ df['distance'] >= min_distance ]\n",
        "\n",
        "  return df"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5erF_k0uKLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfca372f-4036-41c4-c092-d947052c950b"
      },
      "source": [
        "pd.set_option('max_columns', 10, 'display.expand_frame_repr', False)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "param_dict = {  \n",
        "    \"in_file\": \"https://raw.githubusercontent.com/kxk302/HIV/main/data/HIV_V3_codonmsa_macse_pre.tsv\",\n",
        "    \"min_support\": 0.010, \n",
        "    \"min_confidence\": 0.500, \n",
        "    \"min_lift\": 2.0, \n",
        "    \"min_conviction\": 2.0, \n",
        "    \"max_len\": 2\n",
        "}\n",
        "\n",
        "hiv_rules = get_association_rules_param(param_dict)\n",
        "\n",
        "# Filter rules based on distance between head and tail positions\n",
        "hiv_rules = filter_rules_based_on_distance(hiv_rules, 15)\n",
        "\n",
        "num_rules = hiv_rules.shape[0]\n",
        "hiv_rules_sorted = hiv_rules.sort_values('distance', ascending=False)\n",
        "print('Number of rules: {}'.format(num_rules))\n",
        "print('HIV dataset association rules: ')\n",
        "print(hiv_rules_sorted.head(num_rules))\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rules: 17\n",
            "HIV dataset association rules: \n",
            "    antecedents consequents  antecedent support  consequent support   support  confidence       lift  leverage  conviction  distance\n",
            "143       (G27)      (T159)            0.016224            0.248525  0.011799    0.727273   2.926356  0.007767    2.755408       132\n",
            "85        (C37)      (T159)            0.089971            0.248525  0.067847    0.754098   3.034295  0.045487    3.055998       122\n",
            "193       (T13)       (T85)            0.029499            0.107670  0.018437    0.625000   5.804795  0.015260    2.379548        72\n",
            "29        (G76)        (A8)            0.015487            0.353245  0.012537    0.809524   2.291679  0.007066    3.395465        68\n",
            "126       (G12)       (G52)            0.121681            0.328171  0.083333    0.684848   2.086864  0.043401    2.131765        40\n",
            "168       (G51)       (T12)            0.030236            0.169617  0.019174    0.634146   3.738706  0.014046    2.269715        39\n",
            "155       (T82)       (G45)            0.013274            0.185841  0.011062    0.833333   4.484127  0.008595    4.884956        37\n",
            "111       (C49)       (T12)            0.067109            0.169617  0.058260    0.868132   5.118204  0.046877    6.297075        37\n",
            "57        (C16)       (G52)            0.022861            0.328171  0.018437    0.806452   2.457412  0.010934    3.471116        36\n",
            "55        (C16)       (G51)            0.022861            0.030236  0.016224    0.709677  23.471282  0.015533    3.340298        35\n",
            "137       (G17)       (G52)            0.022124            0.328171  0.016224    0.733333   2.234607  0.008964    2.519358        35\n",
            "54        (G51)       (C16)            0.030236            0.022861  0.016224    0.536585  23.471282  0.015533    2.108562        35\n",
            "160       (T13)       (G48)            0.029499            0.191003  0.022124    0.750000   3.926641  0.016490    3.235988        35\n",
            "11        (A17)       (G52)            0.015487            0.328171  0.011799    0.761905   2.321669  0.006717    2.821681        35\n",
            "52        (C16)       (C49)            0.022861            0.067109  0.016962    0.741935  11.055654  0.015427    3.614952        33\n",
            "38        (A84)       (G52)            0.185841            0.328171  0.151917    0.817460   2.490958  0.090930    3.680454        32\n",
            "175       (T25)       (G52)            0.034661            0.328171  0.023599    0.680851   2.074683  0.012224    2.105064        27\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}